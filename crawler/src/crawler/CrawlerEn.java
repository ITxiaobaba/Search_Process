package crawler;import java.io.BufferedReader;import java.io.IOException;import java.io.InputStreamReader;import java.net.HttpURLConnection;import java.net.URL;import java.sql.PreparedStatement;import java.sql.ResultSet;import java.sql.SQLException;import java.sql.Statement;import java.util.ArrayList;import java.util.regex.Matcher;import java.util.regex.Pattern;public class CrawlerEn {    /**     * 要分析的网页     */    String htmlUrl;    /**     * 分析结果     */    ArrayList<String> hrefList = new ArrayList();    /**     * 网页编码方式     */    String charSet;    public static DB db = new DB();    public CrawlerEn(String htmlUrl) {        // TODO 自动生成的构造函数存根        this.htmlUrl = htmlUrl;    }    /**     * 获取分析结果     *     * @throws IOException     */    public ArrayList<String> getHrefList() throws IOException {        parser();        return hrefList;    }    /**     * 解析网页链接     *     * @return     * @throws IOException     */    private void parser() throws IOException {        URL url = new URL(htmlUrl);        HttpURLConnection connection = (HttpURLConnection) url.openConnection();        connection.setDoOutput(true);        String contenttype = connection.getContentType();        System.out.println(contenttype);        charSet = getCharset(contenttype);        System.out.println(charSet);        InputStreamReader isr = new InputStreamReader(                connection.getInputStream());        BufferedReader br = new BufferedReader(isr);        String str = null, rs = null;        while ((str = br.readLine()) != null) {            rs = getHref(str);            if (rs != null)                hrefList.add(rs);        }    }    /**     * 获取网页编码方式     *     * @param str     */    private String getCharset(String str) {        Pattern pattern = Pattern.compile("charset=.*");        Matcher matcher = pattern.matcher(str);        if (matcher.find())            return matcher.group(0).split("charset=")[1];        return null;    }    /**     * 从一行字符串中读取链接     *     * @return     */    private String getHref(String str) {        Pattern pattern = Pattern.compile("http://www.xinhuanet.com/english/2019-.*htm");        Matcher matcher = pattern.matcher(str);        if (matcher.find())            return matcher.group(0);        return null;    }    public static void processUrl(String url) throws SQLException, IOException {//检查一下是否给定的URL已经存在数据库中        String sql = "select * from enrecord where URL='" + url + "'";        ResultSet rs = db.runSql(sql);        if (!rs.next()) {            //将URL存储到数据库中避免下次重复            String sql2 = "insert into enrecord (URL) values " + "(?)";            PreparedStatement stmt = db.conn.prepareStatement(sql2, Statement.RETURN_GENERATED_KEYS);            stmt.setString(1, url);            stmt.execute();            System.out.println(url);        }    }    public static void main(String[] arg) throws IOException, SQLException {            String str = "https://www.wuxiaworld.com/novel/a-will-eternal/";            CrawlerEn a = new CrawlerEn(str);            ArrayList<String> hrefList = a.getHrefList();            for (int j = 0; j < hrefList.size(); j++) {                processUrl(hrefList.get(j));            }    }}