package crawler;import org.jsoup.*;import org.jsoup.Connection;import org.jsoup.nodes.Document;import org.jsoup.nodes.Element;import org.jsoup.select.Elements;public class Main {//    public static void main(String[] args){//        Html html=new Html();//       int i=0;//       html.getHtmlTextByPath("xinwen4"+i,"http://www.kankanews.com/a/2019-05-09/0038845766.shtml");//        String url="http://www.kankanews.com/a/2019-05-09/0038845766.shtml";//       MyCrawler myCrawler=new MyCrawler();//        String result=myCrawler.SendGet(url);//        System.out.print(result);//    }    private static String url = "http://www.enread.com/story/love/105552.html";    public static void main(String[] args) throws Exception {        //链接到目标地址        Connection connect = Jsoup.connect(url);        //设置useragent,设置超时时间，并以get请求方式请求服务器        Document document = connect.userAgent("Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)").timeout(6000).ignoreContentType(true).get();        Thread.sleep(1000);        //获取指定标签的数据        Element elementById = document.getElementById("dede_content");        //输出文本数据        System.out.println(elementById.text());        //输出html数据       // System.out.println(elementById.html());    }}